{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ YouTube Search Scraper for NotebookLM\n",
    "\n",
    "Automatically find YouTube videos and format them for bulk import into Google NotebookLM.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Run all cells in order to:\n",
    "1. Install dependencies\n",
    "2. Configure the scraper\n",
    "3. Run the scrape\n",
    "4. Download results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install all required Python packages. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install selenium webdriver-manager pandas requests colorama ipywidgets\n",
    "\n",
    "# Install Chrome browser (required for Colab)\n",
    "!apt-get update\n",
    "!apt-get install -y chromium-browser\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Search\n",
    "\n",
    "Enter your search term and configure search options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INTERACTIVE SEARCH WIDGET IMPLEMENTATION ===\n",
    "# This widget allows you to specify any search term\n",
    "# The search term you enter will be used EXACTLY as typed\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration dictionary for search preferences\n",
    "SEARCH_CONFIG = {\n",
    "    'term': '',  # Default search term (empty - user must provide)\n",
    "    'title_filter': True,  # By default, filter videos to only include those with search term in title\n",
    "    'configured': False, # Track if user has set a search term\n",
    "}\n",
    "\n",
    "# Text input widget for entering the search term\n",
    "search_text = widgets.Text(\n",
    "    value=SEARCH_CONFIG['term'],\n",
    "    placeholder='Enter search term (e.g., \"football highlights\", \"cooking recipes\", \"stock market\")',\n",
    "    description='Search Term:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Checkbox to control title filtering\n",
    "title_filter_checkbox = widgets.Checkbox(\n",
    "    value=SEARCH_CONFIG['title_filter'],\n",
    "    description='Only include videos with search term in title',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "# Button to confirm search settings\n",
    "search_button = widgets.Button(\n",
    "    description='Set Search Term',\n",
    "    disabled=False,\n",
    "    button_style='primary',\n",
    "    tooltip='Click to update search term',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "# Function that runs when the button is clicked\n",
    "def on_button_click(b):\n",
    "    if not search_text.value.strip():\n",
    "        print(\"‚ö†Ô∏è Please enter a search term before proceeding.\")\n",
    "        return\n",
    "        \n",
    "    SEARCH_CONFIG['term'] = search_text.value\n",
    "    SEARCH_CONFIG['title_filter'] = title_filter_checkbox.value\n",
    "    SEARCH_CONFIG['configured'] = True  # Mark as configured\n",
    "    print(f\"‚úÖ Search term set to: '{SEARCH_CONFIG['term']}'\")\n",
    "    print(f\"‚úÖ Title filtering: {'Enabled' if SEARCH_CONFIG['title_filter'] else 'Disabled'}\")\n",
    "    print(\"‚úÖ Ready to run scraper!\")\n",
    "\n",
    "# Connect the function to the button\n",
    "search_button.on_click(on_button_click)\n",
    "\n",
    "# Display instructions and widgets\n",
    "display(HTML(\"<h3>üìå Configure YouTube Search</h3>\"))\n",
    "display(HTML(\"<p>Enter what you want to search for on YouTube:</p>\"))\n",
    "display(search_text)\n",
    "display(title_filter_checkbox)\n",
    "display(search_button)\n",
    "display(HTML(\"<p><em>Important: Click the button after entering your search term!</em></p>\"))\n",
    "\n",
    "print(\"‚úÖ Search widget initialized. Enter your search term and click 'Set Search Term'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries and Setup\n",
    "\n",
    "Import all necessary libraries and set up the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Any\n",
    "from urllib.parse import urlencode, urlparse, parse_qs\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "\n",
    "Configure the scraper settings. You can modify these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "CONFIG = {\n",
    "    'debug': False,\n",
    "    'max_videos': 100,  # Maximum videos to collect\n",
    "    'headless': True,\n",
    "    'scroll_pause_time': 2.0,\n",
    "    'max_videos_per_search': 50,\n",
    "    'page_load_timeout': 30,\n",
    "    'implicit_wait': 10,\n",
    "}\n",
    "\n",
    "# YouTube search configuration\n",
    "YOUTUBE_CONFIG = {\n",
    "    'base_url': 'https://www.youtube.com',\n",
    "    'search_path': '/results',\n",
    "    'today_filter': 'CAISBAgBEAE%253D',\n",
    "    'video_selector': 'ytd-video-renderer,ytd-grid-video-renderer',\n",
    "    'title_selector': '#video-title',\n",
    "    'channel_selector': '#channel-name,#text',\n",
    "    'duration_selector': '#text.ytd-thumbnail-overlay-time-status-renderer',\n",
    "    'views_selector': '#metadata-line span:nth-child(1)',\n",
    "    'upload_time_selector': '#metadata-line span:nth-child(2)',\n",
    "}\n",
    "\n",
    "# Date formats for search terms\n",
    "DATE_FORMATS = [\n",
    "    '%m/%d/%Y',  # 10/19/2023\n",
    "    '%m-%d-%Y',  # 10-19-2023\n",
    "    '%B %d, %Y', # October 19, 2023\n",
    "    '%b %d, %Y', # Oct 19, 2023\n",
    "    '%Y-%m-%d',  # 2023-10-19\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Configuration loaded!\")\n",
    "if SEARCH_CONFIG.get('configured', False) and SEARCH_CONFIG['term'].strip():\n",
    "    print(f\"üìä Will search for up to {CONFIG['max_videos']} videos matching: '{SEARCH_CONFIG['term']}'\")\n",
    "else:\n",
    "    print(\"üìä Search term not configured yet. Set it in Cell 2 before running the scraper.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scraper Class\n",
    "\n",
    "Define the main YouTube search scraper class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeSearchScraper:\n",
    "    \"\"\"YouTube scraper for any search term\"\"\"\n",
    "\n",
    "    def __init__(self, headless: bool = True, debug: bool = False, search_config: Optional[Dict] = None):\n",
    "        self.headless = headless\n",
    "        self.debug = debug\n",
    "        self.driver = None\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.search_config = search_config or SEARCH_CONFIG\n",
    "\n",
    "        # Configure logging\n",
    "        if debug:\n",
    "            logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        else:\n",
    "            logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "    def setup_driver(self) -> None:\n",
    "        \"\"\"Configure and initialize Chrome WebDriver for Colab\"\"\"\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "\n",
    "            # Colab-specific options\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_options.add_argument('--disable-gpu')\n",
    "            chrome_options.add_argument('--disable-extensions')\n",
    "            chrome_options.add_argument('--disable-background-timer-throttling')\n",
    "            chrome_options.add_argument('--disable-backgrounding-occluded-windows')\n",
    "            chrome_options.add_argument('--disable-renderer-backgrounding')\n",
    "            chrome_options.add_argument('--disable-features=VizDisplayCompositor')\n",
    "\n",
    "            if self.headless:\n",
    "                chrome_options.add_argument('--headless')\n",
    "\n",
    "            # Set binary location for Colab\n",
    "            chrome_options.binary_location = '/usr/bin/chromium-browser'\n",
    "\n",
    "            # Anti-detection measures\n",
    "            chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "            chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "            chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "            # User agent\n",
    "            chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "\n",
    "            # Window size\n",
    "            chrome_options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "            # Initialize driver\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "            # Set timeouts\n",
    "            self.driver.set_page_load_timeout(CONFIG['page_load_timeout'])\n",
    "            self.driver.implicitly_wait(CONFIG['implicit_wait'])\n",
    "\n",
    "            # Execute script to remove webdriver property\n",
    "            self.driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "            self.logger.info(\"Chrome driver initialized successfully for Colab\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to setup Chrome driver: {e}\")\n",
    "            raise\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Close browser and cleanup resources\"\"\"\n",
    "        if self.driver:\n",
    "            try:\n",
    "                self.driver.quit()\n",
    "                self.logger.info(\"Browser closed successfully\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error closing browser: {e}\")\n",
    "            finally:\n",
    "                self.driver = None\n",
    "\n",
    "    def get_default_search_terms(self) -> List[str]:\n",
    "        \"\"\"Get search term directly from user input\"\"\"\n",
    "        # Return a list containing only the exact search term\n",
    "        return [self.search_config['term']]\n",
    "\n",
    "    def build_search_url(self, search_term: str) -> str:\n",
    "        \"\"\"Build YouTube search URL with 'Today' filter\"\"\"\n",
    "        base_url = f\"{YOUTUBE_CONFIG['base_url']}{YOUTUBE_CONFIG['search_path']}\"\n",
    "\n",
    "        params = {\n",
    "            'search_query': search_term,\n",
    "            'sp': YOUTUBE_CONFIG['today_filter']  # Today filter\n",
    "        }\n",
    "\n",
    "        return f\"{base_url}?{urlencode(params)}\"\n",
    "\n",
    "    def scroll_for_videos(self, target_count: int, max_scrolls: int = 10) -> bool:\n",
    "        \"\"\"Scroll down to load more videos. Returns True if target reached.\"\"\"\n",
    "        if not self.driver:\n",
    "            return False\n",
    "\n",
    "        last_height = self.driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        scrolls = 0\n",
    "\n",
    "        while scrolls < max_scrolls:\n",
    "            # Scroll to bottom\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "            # Wait for new content to load\n",
    "            time.sleep(CONFIG['scroll_pause_time'])\n",
    "\n",
    "            # Check if we've reached target count\n",
    "            video_elements = self.driver.find_elements(By.CSS_SELECTOR, YOUTUBE_CONFIG['video_selector'])\n",
    "            if len(video_elements) >= target_count:\n",
    "                self.logger.info(f\"Reached target video count: {len(video_elements)}\")\n",
    "                return True\n",
    "\n",
    "            # Check if page height changed\n",
    "            new_height = self.driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                self.logger.info(\"No more content to load\")\n",
    "                break\n",
    "\n",
    "            last_height = new_height\n",
    "            scrolls += 1\n",
    "            self.logger.debug(f\"Scroll {scrolls}, videos found: {len(video_elements)}\")\n",
    "\n",
    "        return False\n",
    "\n",
    "    def extract_video_data(self, video_element) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Extract video data from a video element\"\"\"\n",
    "        try:\n",
    "            # Extract URL\n",
    "            title_link = video_element.find_element(By.CSS_SELECTOR, YOUTUBE_CONFIG['title_selector'])\n",
    "            url = title_link.get_attribute('href')\n",
    "\n",
    "            if not url or 'watch?v=' not in url:\n",
    "                return None\n",
    "\n",
    "            # Extract title\n",
    "            title = title_link.get_attribute('title') or title_link.text.strip()\n",
    "\n",
    "            # Check if title contains the search term (case insensitive) - only if filter is enabled\n",
    "            if self.search_config['title_filter']:\n",
    "                title_lower = title.lower()\n",
    "                search_term_lower = self.search_config['term'].lower()\n",
    "                if search_term_lower not in title_lower:\n",
    "                    return None  # Skip videos that don't mention the search term in title\n",
    "\n",
    "            # Extract channel\n",
    "            try:\n",
    "                channel_element = video_element.find_element(By.CSS_SELECTOR, YOUTUBE_CONFIG['channel_selector'])\n",
    "                channel = channel_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                channel = \"Unknown\"\n",
    "\n",
    "            # Extract duration\n",
    "            try:\n",
    "                duration_element = video_element.find_element(By.CSS_SELECTOR, YOUTUBE_CONFIG['duration_selector'])\n",
    "                duration = duration_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                duration = \"Unknown\"\n",
    "\n",
    "            # Extract views and upload time\n",
    "            try:\n",
    "                metadata_elements = video_element.find_elements(By.CSS_SELECTOR, '#metadata-line span')\n",
    "                views = metadata_elements[0].text.strip() if len(metadata_elements) > 0 else \"Unknown\"\n",
    "                upload_time = metadata_elements[1].text.strip() if len(metadata_elements) > 1 else \"Unknown\"\n",
    "            except (NoSuchElementException, IndexError):\n",
    "                views = \"Unknown\"\n",
    "                upload_time = \"Unknown\"\n",
    "\n",
    "            # Extract video ID from URL\n",
    "            parsed_url = urlparse(url)\n",
    "            video_id = parse_qs(parsed_url.query).get('v', [None])[0]\n",
    "\n",
    "            if not video_id:\n",
    "                return None\n",
    "\n",
    "            return {\n",
    "                'video_id': video_id,\n",
    "                'url': f\"https://www.youtube.com/watch?v={video_id}\",\n",
    "                'title': title,\n",
    "                'channel': channel,\n",
    "                'duration': duration,\n",
    "                'views': views,\n",
    "                'upload_time': upload_time,\n",
    "                'scraped_at': datetime.now().isoformat(),\n",
    "                'search_term': getattr(self, '_current_search_term', 'Unknown'),\n",
    "                'filter_term': self.search_config['term']\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.debug(f\"Error extracting video data: {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_search_term(self, search_term: str, max_videos: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Scrape videos for a specific search term\"\"\"\n",
    "        self._current_search_term = search_term\n",
    "        videos = []\n",
    "\n",
    "        try:\n",
    "            # For date-based searches, don't use the \"Today\" filter\n",
    "            if any(date_str in search_term.lower() for date_str in [\n",
    "                datetime.now().strftime(fmt).lower() for fmt in DATE_FORMATS\n",
    "            ]):\n",
    "                # Use regular search without \"Today\" filter for date-specific searches\n",
    "                search_url = f\"{YOUTUBE_CONFIG['base_url']}{YOUTUBE_CONFIG['search_path']}?search_query={search_term}\"\n",
    "            else:\n",
    "                # Use \"Today\" filter for general searches\n",
    "                search_url = self.build_search_url(search_term)\n",
    "\n",
    "            self.logger.info(f\"Searching: {search_term}\")\n",
    "\n",
    "            self.driver.get(search_url)\n",
    "\n",
    "            # Wait for initial results to load\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, YOUTUBE_CONFIG['video_selector']))\n",
    "            )\n",
    "\n",
    "            # Scroll to load more videos\n",
    "            self.scroll_for_videos(max_videos)\n",
    "\n",
    "            # Extract video data\n",
    "            video_elements = self.driver.find_elements(By.CSS_SELECTOR, YOUTUBE_CONFIG['video_selector'])\n",
    "\n",
    "            for element in video_elements[:max_videos]:\n",
    "                video_data = self.extract_video_data(element)\n",
    "                if video_data:\n",
    "                    videos.append(video_data)\n",
    "\n",
    "            self.logger.info(f\"Found {len(videos)} videos matching '{search_term}'\")\n",
    "\n",
    "        except TimeoutException:\n",
    "            self.logger.warning(f\"Timeout loading search results for '{search_term}'\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error scraping '{search_term}': {e}\")\n",
    "\n",
    "        return videos\n",
    "\n",
    "    def search_youtube(self, search_terms: Optional[List[str]] = None, max_videos: int = 50) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Main search method - search YouTube for content matching the search term\"\"\"\n",
    "        if not self.driver:\n",
    "            self.setup_driver()\n",
    "\n",
    "        if search_terms is None:\n",
    "            search_terms = self.get_default_search_terms()\n",
    "\n",
    "        all_videos = []\n",
    "        seen_urls = set()\n",
    "\n",
    "        self.logger.info(f\"Starting scrape with search term: '{self.search_config['term']}', max {max_videos} videos total\")\n",
    "\n",
    "        for term in search_terms:\n",
    "            if len(all_videos) >= max_videos:\n",
    "                break\n",
    "\n",
    "            remaining = max_videos - len(all_videos)\n",
    "            term_videos = self.scrape_search_term(term, CONFIG['max_videos_per_search'])\n",
    "\n",
    "            # Filter out duplicates\n",
    "            for video in term_videos:\n",
    "                if video['url'] not in seen_urls and len(all_videos) < max_videos:\n",
    "                    all_videos.append(video)\n",
    "                    seen_urls.add(video['url'])\n",
    "\n",
    "            # Small delay between searches to be respectful\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.logger.info(f\"Scraping complete. Found {len(all_videos)} unique videos\")\n",
    "        return all_videos\n",
    "\n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager entry\"\"\"\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit\"\"\"\n",
    "        self.cleanup()\n",
    "\n",
    "print(\"‚úÖ YouTubeSearchScraper class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Output Formatter Class\n",
    "\n",
    "Define the formatter class for generating different output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLFormatter:\n",
    "    \"\"\"Handles formatting and saving of scraped video data\"\"\"\n",
    "\n",
    "    def __init__(self, search_config=None):\n",
    "        self.search_config = search_config or SEARCH_CONFIG\n",
    "\n",
    "    def format_for_bulk_import(self, videos: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format URLs for bulk import (one URL per line)\"\"\"\n",
    "        urls = [video['url'] for video in videos if video.get('url')]\n",
    "        return '\\n'.join(urls)\n",
    "\n",
    "    def format_with_metadata(self, videos: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format videos with detailed metadata in readable text format\"\"\"\n",
    "        lines = []\n",
    "        search_term = self.search_config['term'].title()  # Capitalized for display\n",
    "        lines.append(f\"{search_term} YouTube Videos\")\n",
    "        lines.append(\"=\" * 50)\n",
    "        lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        lines.append(f\"Total videos: {len(videos)}\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        for i, video in enumerate(videos, 1):\n",
    "            lines.append(f\"{i}. {video.get('title', 'Unknown Title')}\")\n",
    "            lines.append(f\"   URL: {video.get('url', 'N/A')}\")\n",
    "            lines.append(f\"   Channel: {video.get('channel', 'Unknown')}\")\n",
    "            lines.append(f\"   Duration: {video.get('duration', 'Unknown')}\")\n",
    "            lines.append(f\"   Views: {video.get('views', 'Unknown')}\")\n",
    "            lines.append(f\"   Uploaded: {video.get('upload_time', 'Unknown')}\")\n",
    "            lines.append(f\"   Scraped from: {video.get('search_term', 'Unknown')}\")\n",
    "            lines.append(\"\")\n",
    "\n",
    "        return '\\n'.join(lines)\n",
    "\n",
    "    def create_dataframe(self, videos: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "        \"\"\"Create pandas DataFrame from video data\"\"\"\n",
    "        if not videos:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Select columns to include\n",
    "        columns = ['video_id', 'url', 'title', 'channel', 'duration', 'views', 'upload_time', 'search_term', 'filter_term']\n",
    "\n",
    "        data = []\n",
    "        for video in videos:\n",
    "            row = {col: video.get(col, '') for col in columns}\n",
    "            data.append(row)\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "print(\"‚úÖ URLFormatter class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Scraper\n",
    "\n",
    "Execute the YouTube search scraper. This will take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if search term has been configured\n",
    "if not SEARCH_CONFIG.get('configured', False):\n",
    "    print(\"‚ùå ERROR: No search term configured!\")\n",
    "    print(\"   Go back to Cell 2, enter a search term, and click 'Set Search Term'.\")\n",
    "    print(\"   Then run this cell again.\")\n",
    "    raise SystemExit(\"Execution stopped: Search term required\")\n",
    "\n",
    "if not SEARCH_CONFIG['term'].strip():\n",
    "    print(\"‚ùå ERROR: Search term is empty!\")\n",
    "    print(\"   Go back to Cell 2 and enter a valid search term.\")\n",
    "    raise SystemExit(\"Execution stopped: Empty search term\")\n",
    "\n",
    "# Initialize scraper and formatter\n",
    "print(f\"üöÄ Initializing YouTube Search Scraper for '{SEARCH_CONFIG['term']}'...\")\n",
    "scraper = YouTubeSearchScraper(headless=CONFIG['headless'], debug=CONFIG['debug'], search_config=SEARCH_CONFIG)\n",
    "formatter = URLFormatter(search_config=SEARCH_CONFIG)\n",
    "\n",
    "# Run the scrape\n",
    "print(f\"üîç Starting YouTube search for '{SEARCH_CONFIG['term']}' content...\")\n",
    "videos = scraper.search_youtube(max_videos=CONFIG['max_videos'])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n‚úÖ Found {len(videos)} videos matching '{SEARCH_CONFIG['term']}'!\")\n",
    "\n",
    "if videos:\n",
    "    print(\"\\nüìä Sample Results:\")\n",
    "    for i, video in enumerate(videos[:3], 1):\n",
    "        print(f\"{i}. {video['title'][:60]}...\")\n",
    "        print(f\"   Channel: {video['channel']}\")\n",
    "        print(f\"   Views: {video['views']}\")\n",
    "        print(f\"   URL: {video['url']}\")\n",
    "        print()\n",
    "\n",
    "# Cleanup\n",
    "scraper.cleanup()\n",
    "print(\"üßπ Browser cleanup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Output Files\n",
    "\n",
    "Create different output formats from the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate timestamp for filenames\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "search_term_slug = SEARCH_CONFIG['term'].lower().replace(' ', '_')\n",
    "\n",
    "if videos:\n",
    "    print(\"üìÅ Generating output files...\")\n",
    "\n",
    "    # 1. Bulk import format (for NotebookLM)\n",
    "    bulk_content = formatter.format_for_bulk_import(videos)\n",
    "    bulk_filename = f'{search_term_slug}_bulk_import_{timestamp}.txt'\n",
    "    with open(bulk_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(bulk_content)\n",
    "    print(f\"‚úì Created {bulk_filename} ({len(videos)} URLs)\")\n",
    "\n",
    "    # 2. Detailed text format\n",
    "    detailed_content = formatter.format_with_metadata(videos)\n",
    "    detailed_filename = f'{search_term_slug}_detailed_{timestamp}.txt'\n",
    "    with open(detailed_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(detailed_content)\n",
    "    print(f\"‚úì Created {detailed_filename}\")\n",
    "\n",
    "    # 3. CSV format\n",
    "    df = formatter.create_dataframe(videos)\n",
    "    csv_filename = f'{search_term_slug}_data_{timestamp}.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"‚úì Created {csv_filename}\")\n",
    "\n",
    "    # 4. JSON format\n",
    "    json_filename = f'{search_term_slug}_data_{timestamp}.json'\n",
    "    import json\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'metadata': {\n",
    "                'generated_at': datetime.now().isoformat(),\n",
    "                'total_videos': len(videos),\n",
    "                'search_term': SEARCH_CONFIG['term'],\n",
    "                'source': 'YouTube Search Scraper'\n",
    "            },\n",
    "            'videos': videos\n",
    "        }, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úì Created {json_filename}\")\n",
    "\n",
    "    print(\"\\n‚úÖ All output files generated successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No videos found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Display Results Summary\n",
    "\n",
    "Show a summary of the scraping results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if videos:\n",
    "    search_term = SEARCH_CONFIG['term']\n",
    "    print(f\"üìä '{search_term}' Search Results Summary\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Basic stats\n",
    "    print(f\"Total videos found: {len(videos)}\")\n",
    "\n",
    "    # Channel breakdown\n",
    "    channels = {}\n",
    "    for video in videos:\n",
    "        channel = video.get('channel', 'Unknown')\n",
    "        channels[channel] = channels.get(channel, 0) + 1\n",
    "\n",
    "    print(f\"Unique channels: {len(channels)}\")\n",
    "    if channels:\n",
    "        top_channel = max(channels.items(), key=lambda x: x[1])\n",
    "        print(f\"Top channel: {top_channel[0]} ({top_channel[1]} videos)\")\n",
    "\n",
    "    # Show top 5 channels\n",
    "    print(\"\\nTop 5 Channels:\")\n",
    "    sorted_channels = sorted(channels.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (channel, count) in enumerate(sorted_channels[:5], 1):\n",
    "        print(f\"{i}. {channel}: {count} videos\")\n",
    "\n",
    "    print(\"\\nüìÅ Output Files:\")\n",
    "    search_term_slug = search_term.lower().replace(' ', '_')\n",
    "    print(f\"‚Ä¢ {search_term_slug}_bulk_import_{timestamp}.txt - URLs for NotebookLM bulk import\")\n",
    "    print(f\"‚Ä¢ {search_term_slug}_detailed_{timestamp}.txt - Detailed video information\")\n",
    "    print(f\"‚Ä¢ {search_term_slug}_data_{timestamp}.csv - Spreadsheet format\")\n",
    "    print(f\"‚Ä¢ {search_term_slug}_data_{timestamp}.json - Complete structured data\")\n",
    "\n",
    "    print(\"\\nüéØ Next Steps:\")\n",
    "    print(\"1. Download the bulk_import_*.txt file\")\n",
    "    print(\"2. Go to NotebookLM (notebooklm.google.com)\")\n",
    "    print(\"3. Use 'Bulk import' feature with the URLs\")\n",
    "    print(f\"4. Enjoy your '{search_term}' video collection!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No videos were found. Try running the scraper again or check your internet connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Display Bulk Import URLs\n",
    "\n",
    "Here are your YouTube URLs ready for NotebookLM bulk import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display bulk import URLs for easy copying\n",
    "if videos:\n",
    "    search_term = SEARCH_CONFIG['term'].upper()\n",
    "    print(f\"üìã {search_term} YOUTUBE URLs - Copy these for NotebookLM Bulk Import\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total videos: {len(videos)}\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    # Display URLs one per line (just the URLs for easy copying)\n",
    "    for video in videos:\n",
    "        print(video['url'])\n",
    "\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üí° Copy these URLs and paste them into NotebookLM's bulk import feature!\")\n",
    "    print(\"   Go to notebooklm.google.com ‚Üí Create/Open notebook ‚Üí Bulk import\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No videos found to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Complete!\n",
    "\n",
    "Your YouTube Search Scraper has successfully found and formatted videos for NotebookLM bulk import!\n",
    "\n",
    "**Copy the URLs from Cell 10 and paste them directly into NotebookLM.** üöÄ\n",
    "\n",
    "### Important Notes:\n",
    "\n",
    "- To perform a different search, simply change the search term in the widget and run the cells again\n",
    "- The title filter option lets you control whether videos must contain your search term in the title\n",
    "- Output files are named based on your search term for easy organization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}